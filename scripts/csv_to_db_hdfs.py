import os
import subprocess
import psycopg2
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# PostgreSQL ì—°ê²° ì •ë³´
DB_CONFIG = {
    "host": os.getenv("DB_HOST"),
    "port": os.getenv("DB_PORT"),
    "dbname": os.getenv("DB_NAME"),
    "user": os.getenv("DB_USER"),
    "password": os.getenv("DB_PASS")
}

# HDFS ë¡œê·¸ íŒŒì¼ ë””ë ‰í„°ë¦¬
HDFS_CSV_LOG_DIR = os.getenv("HDFS_CSV_LOG_DIR", "logs")
HDFS_CSV_LOG_FILE = os.path.join(HDFS_CSV_LOG_DIR, "hdfs_csv_paths.log")


def read_hdfs_csv_log():
    """ğŸ“‚ HDFS CSV ë¡œê·¸ íŒŒì¼ì—ì„œ íŒŒì¼ ê²½ë¡œ ëª©ë¡ì„ ì½ì–´ì˜´"""
    if not os.path.exists(HDFS_CSV_LOG_FILE):
        print(f"âš ï¸ ë¡œê·¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {HDFS_CSV_LOG_FILE}")
        return []

    with open(HDFS_CSV_LOG_FILE, "r") as file:
        return [line.strip() for line in file if line.strip()]


def update_hdfs_csv_log(remaining_paths):
    """ğŸ“ ì²˜ë¦¬ í›„ ë‚¨ì€ HDFS CSV ê²½ë¡œ ëª©ë¡ì„ ë¡œê·¸ íŒŒì¼ì— ë‹¤ì‹œ ì €ì¥"""
    with open(HDFS_CSV_LOG_FILE, "w") as file:
        file.writelines(f"{path}\n" for path in remaining_paths)


def create_stock_data_table():
    """ğŸ“Š stock_data í…Œì´ë¸” ìƒì„±"""
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS stock_data (
        id BIGSERIAL PRIMARY KEY,
        ticker TEXT NOT NULL,
        date DATE NOT NULL,
        open NUMERIC,
        high NUMERIC,
        low NUMERIC,
        close NUMERIC,
        volume BIGINT,
        UNIQUE (ticker, date)
    );
    """)
    conn.commit()
    cur.close()
    conn.close()


def create_temp_table():
    """ğŸ“Œ stock_data_temp í…Œì´ë¸” ìƒì„±"""
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS stock_data_temp (
        ticker TEXT,
        date DATE,
        open NUMERIC,
        high NUMERIC,
        low NUMERIC,
        close NUMERIC,
        volume BIGINT
    );
    """)
    conn.commit()
    cur.close()
    conn.close()


def hdfs_to_temp_table(hdfs_path):
    """ğŸ“¥ HDFSì—ì„œ CSV íŒŒì¼ì„ ì½ì–´ PostgreSQL ì„ì‹œ í…Œì´ë¸”ì— ì ì¬"""
    create_temp_table()

    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()

    try:
        # HDFSì—ì„œ íŒŒì¼ ë‚´ìš©ì„ ì§ì ‘ ì½ì–´ COPY ì‹¤í–‰
        hdfs_cmd = ["hdfs", "dfs", "-cat", hdfs_path]
        process = subprocess.Popen(hdfs_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        copy_query = """
        COPY stock_data_temp (ticker, date, open, high, low, close, volume)
        FROM STDIN WITH CSV HEADER DELIMITER ',' QUOTE '"';
        """
        cur.copy_expert(sql=copy_query, file=process.stdout)

        conn.commit()
        print(f"âœ… HDFS ë°ì´í„° ì ì¬ ì™„ë£Œ: {hdfs_path}")
        return True

    except Exception as e:
        print(f"âŒ HDFS ë°ì´í„° ì ì¬ ì‹¤íŒ¨: {e}")
        return False

    finally:
        cur.close()
        conn.close()


def move_data_from_temp_to_main():
    """ğŸ“¤ stock_data_temp â†’ stock_data í…Œì´ë¸”ë¡œ ë°ì´í„° ì´ë™"""
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()

    cur.execute("""
    INSERT INTO stock_data (ticker, date, open, high, low, close, volume)
    SELECT ticker, date, open, high, low, close, volume
    FROM stock_data_temp
    ON CONFLICT (ticker, date) DO NOTHING;
    """)

    conn.commit()
    cur.close()
    conn.close()
    print("âœ… ë°ì´í„° ì´ë™ ì™„ë£Œ")


def drop_temp_table():
    """ğŸ“‚ stock_data_temp í…Œì´ë¸” ì‚­ì œ"""
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()
    cur.execute("DROP TABLE IF EXISTS stock_data_temp;")
    conn.commit()
    cur.close()
    conn.close()


def process_hdfs_csv_files():
    """ğŸ“‚ HDFS CSV ë¡œê·¸ íŒŒì¼ì„ ì½ì–´ ëª¨ë“  CSVë¥¼ ì²˜ë¦¬"""
    hdfs_paths = read_hdfs_csv_log()
    if not hdfs_paths:
        print("âš ï¸ ì²˜ë¦¬í•  HDFS CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    processed_paths = []

    for hdfs_path in hdfs_paths:
        print(f"ğŸ“‚ HDFS íŒŒì¼ ì²˜ë¦¬ ì¤‘: {hdfs_path}")
        success = hdfs_to_temp_table(hdfs_path)
        if success:
            move_data_from_temp_to_main()
            drop_temp_table()
            processed_paths.append(hdfs_path)

    # ë¡œê·¸ íŒŒì¼ ì—…ë°ì´íŠ¸ (ì²˜ë¦¬ëœ íŒŒì¼ ì œê±°)
    remaining_paths = [path for path in hdfs_paths if path not in processed_paths]
    update_hdfs_csv_log(remaining_paths)

    print("âœ… ëª¨ë“  HDFS CSV íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")


if __name__ == "__main__":
    create_stock_data_table()
    process_hdfs_csv_files()
