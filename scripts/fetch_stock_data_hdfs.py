import argparse
import logging
import time
import pandas as pd
import yfinance as yf
import os
from datetime import datetime, timedelta
import pandas_market_calendars as mcal
from dotenv import load_dotenv
import psycopg2
from psycopg2 import sql
from hdfs import InsecureClient


# .env file load
load_dotenv()

# PostgreSQL ì—°ê²° ì •ë³´ ì„¤ì •
DB_CONFIG = {
    "host": os.getenv("DB_HOST"),
    "port": os.getenv("DB_PORT"),
    "dbname": os.getenv("DB_NAME"),
    "user": os.getenv("DB_USER"),
    "password": os.getenv("DB_PASS")
}


# HDFS ì—°ê²° ì •ë³´ ì„¤ì •
HDFS_HOST = os.getenv("HDFS_HOST")
HDFS_PORT = os.getenv("HDFS_PORT")
HDFS_CLIENT = InsecureClient(f'http://{HDFS_HOST}:{HDFS_PORT}')

# CSV ë° TIcker íŒŒì¼ ê²½ë¡œ
CSV_DIR = os.getenv("CSV_DIR")
TICKER_PATH = os.getenv("TICKER_FILE_PATH")
CSV_LOG_DIR = os.getenv("CSV_LOG_DIR")

# ë¡œê·¸ í…Œì´ë¸”ëª… ì§€ì •
LOG_TABLE_NAME = "stock_data_log"



def create_log_table():
    """ ğŸ“‘ ë¡œê·¸ ì €ì¥ì„ ìœ„í•œ í…Œì´ë¸” ìƒì„± í•¨ìˆ˜ """
    create_table_query = sql.SQL(f"""
    CREATE TABLE IF NOT EXISTS {LOG_TABLE_NAME} (
        id SERIAL PRIMARY KEY,
        execution_time TIMESTAMP NOT NULL,
        from_date DATE NOT NULL,
        to_date DATE NOT NULL,
        tickers TEXT NOT NULL,
        step TEXT NOT NULL,
        status TEXT NOT NULL,
        message TEXT,
        duration_seconds DOUBLE PRECISION
    );
    """)

    conn = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        with conn.cursor() as cur:
            cur.execute(create_table_query)
            conn.commit()
    except Exception as e:
        print(f"[ERROR] í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
    finally:
        if conn:
            conn.close()

def is_market_closed(date):
    nyse = mcal.get_calendar("NYSE")
    holidays = nyse.holidays().holidays
    is_weekend = date.weekday() in [5,6]

    return date in holidays or is_weekend

def load_tickers_from_file(file_path: str) -> list:
    """ğŸ“‚ íŒŒì¼ì—ì„œ Ticker ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜"""
    tickers = []
    try:
        with open(file_path, "r") as f:
            tickers = [line.strip() for line in f if line.strip()]  # ë¹ˆ ì¤„ ì œì™¸
        print(f"[INFO] Ticker {len(tickers)}ê°œ ë¡œë“œ ì™„ë£Œ")
    except FileNotFoundError:
        print(f"[ERROR] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    except Exception as e:
        print(f"[ERROR] Ticker íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return tickers

def get_default_dates() -> tuple:
    """ğŸ—“ï¸ ê¸°ë³¸ ë‚ ì§œë¥¼ ì „ë‚ ë¡œ ì„¤ì •"""
    today = datetime.now().strftime("%Y-%m-%d")
    yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")

    return yesterday, today


# ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜
def log_to_db(execution_time, from_date, to_date, tickers, step, status, message, duration_seconds):
    conn = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO stock_data_log 
                (execution_time, from_date, to_date, tickers, step, status, message, duration_seconds) 
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                """,
                (execution_time, from_date, to_date, tickers, step, status, message, duration_seconds)
            )
            conn.commit()
            # print(f"[INFO] ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {step} - {status}")
    except Exception as e:
        print(f"[ERROR] ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    finally:
        if conn:
            conn.close()


def save_csv(data, extract_date, tickers, is_monthly=False):
    """ CSV íŒŒì¼ì„ ì €ì¥í•˜ê³  ë¡œê·¸ë¥¼ ë‚¨ê¸°ëŠ” í•¨ìˆ˜ """
    start_time = datetime.now()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡
    try:
        # ğŸ“… ë‚ ì§œ ê¸°ë°˜ í´ë” êµ¬ì¡° ìƒì„±
        date_folder_base = extract_date.replace("_", "/")[:7]  # "YYYY/MM"
        full_date_folder = extract_date.replace("_", "/")  # "YYYY/MM/DD"

        # âœ… ì›”ë³„/í‹°ì»¤ë³„ ì €ì¥
        if is_monthly:
            save_folder = f"/{CSV_DIR}/{date_folder_base}/date_data"
            file_name = f"ALL_DATA_{extract_date}.csv"
        else:
            save_folder = f"/{CSV_DIR}/{full_date_folder}"
            file_name = f"TICKER_DATA_{tickers}_{extract_date}.csv"

        if not HDFS_CLIENT.status(save_folder, strict=False):
            HDFS_CLIENT.makedirs(save_folder)

        file_path = os.path.join(save_folder, file_name)
        message = f"Data: {file_path} HDFS ì €ì¥ ì™„ë£Œ"

        # CSV ì €ì¥
        with HDFS_CLIENT.write(file_path, encoding='utf-8') as writer:
            data.to_csv(writer, index=False)

        # ì €ì¥ ê²½ë¡œë¥¼ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡ (ì „ì²´ í•˜ë‚˜ë§Œ)
        if is_monthly:
            log_file_path = CSV_LOG_DIR
            with open(log_file_path, "a") as log_file:
                log_file.write(file_path + "\n")

        duration_seconds = (datetime.now() - start_time).total_seconds()
        # ğŸ“ ë¡œê·¸ ì‘ì„±
        log_to_db(
            execution_time=datetime.now(),
            from_date=extract_date,
            to_date=extract_date,
            tickers=tickers,
            step="SAVE_CSV",
            status="SUCCESS",
            message=message,
            duration_seconds=duration_seconds
        )

        return file_path
    except Exception as e:
        duration_seconds = (datetime.now() - start_time).total_seconds()
        # ğŸ“ ë¡œê·¸ ì‘ì„±
        log_to_db(
            execution_time=datetime.now(),
            from_date=extract_date,
            to_date=extract_date,
            tickers=tickers,
            step="SAVE_CSV",
            status="FAIL",
            message=f"CSV ì €ì¥ ì‹¤íŒ¨: {e}",
            duration_seconds=duration_seconds
        )

        return None



# ì£¼ì‹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
def fetch_stock_data(tickers, from_date, to_date):
    ticker_list = ','.join(tickers)

    # âœ… ë°ì´í„° ì¶”ì¶œ ì‹œì‘ ë¡œê·¸
    log_to_db(
        execution_time=datetime.now(),
        from_date=from_date,
        to_date=to_date,
        tickers=ticker_list,
        step="START",
        status="START",
        message="ë°ì´í„° ì¶”ì¶œ ì‹œì‘",
        duration_seconds=0
    )

    start_time = datetime.now()
    retries = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

    for attempt in range(retries):
        try:
            # âœ… Ticker ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´ (MultiIndex DataFrame)
            stock_data = yf.download(tickers, start=from_date, end=to_date, group_by='ticker', threads=True)

            # âœ… ëª¨ë“  ë°ì´í„°ê°€ ë¹„ì–´ ìˆëŠ”ì§€ í™•ì¸
            if stock_data.empty:
                print("[WARN] ëª¨ë“  ë°ì´í„°ê°€ ì—†ìŒ")
                log_to_db(
                    execution_time=start_time,
                    from_date=from_date,
                    to_date=to_date,
                    tickers=ticker_list,
                    step="FETCH_DATA",
                    status="FAIL",
                    message="ëª¨ë“  ë°ì´í„° ì—†ìŒ",
                    duration_seconds=(datetime.now() - start_time).total_seconds()
                )
                return

            valid_tickers = set()  # âœ… ë°ì´í„°ê°€ ìˆëŠ” í‹°ì»¤ ë¦¬ìŠ¤íŠ¸
            data_list = []      # âœ… ìœ íš¨í•œ ë°ì´í„° ì €ì¥

            # âœ… í‹°ì»¤ ëª©ë¡ ì¶”ì¶œ (MultiIndex êµ¬ì¡°ì—ì„œ 2ë²ˆì§¸ ë ˆë²¨ ê°’ ê°€ì ¸ì˜¤ê¸°)
            ticker_in_column = stock_data.stack(level=0, future_stack=True).reset_index()
            # ë°›ì•„ì˜¤ì§€ ëª»í•œ í‹°ì»¤ ëª©ë¡ ì œì™¸
            missing_tickers = [ticker for ticker in tickers if stock_data[ticker].isna().all().all()]

            down_tickers = list(set(tickers) - set(missing_tickers))
            print(f"{missing_tickers} ë¥¼ ì œì™¸í•©ë‹ˆë‹¤.")
            for ticker in down_tickers:
                df_ticker = ticker_in_column[ticker_in_column["Ticker"] == ticker]
                if df_ticker[["Open", "High", "Low", "Close", "Volume"]].isna().all().all():
                    print(f"[WARN] {ticker} ë°ì´í„° ì—†ìŒ")
                    log_to_db(
                        execution_time=start_time,
                        from_date=from_date,
                        to_date=to_date,
                        tickers=ticker,
                        step="FETCH_DATA",
                        status="FAIL",
                        message=str(e),
                        duration_seconds=(datetime.now() - start_time).total_seconds()
                    )
                else:
                    valid_tickers.add(ticker)  # âœ… ë°ì´í„° ìˆëŠ” í‹°ì»¤ë§Œ ì¶”ê°€
                    df_ticker.reset_index(inplace=True)

                    # âœ… í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
                    df_ticker = df_ticker[['Date', 'Ticker', 'Close', 'High', 'Low', 'Open', 'Volume']]
                    data_list.append(df_ticker)


            if not data_list:
                print("[WARN] ëª¨ë“  í‹°ì»¤ì˜ ë°ì´í„°ê°€ ì—†ìŒ")
                return

            # âœ… ëª¨ë“  Ticker ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ ë³‘í•©
            df_final = pd.concat(data_list).reset_index(drop=True)

            # âœ… í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            df_final = df_final[['Date', 'Ticker', 'Close', 'High', 'Low', 'Open', 'Volume']]
            df_final = df_final.dropna()  # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰ ì‚­ì œ
            df_final['Volume'] = df_final['Volume'].astype(int)  # ì •ìˆ˜í˜• ë³€í™˜ ì¶”ê°€

            # âœ… ë‚ ì§œë³„ë¡œ ë‚˜ëˆ  ì €ì¥
            for date, df_date in df_final.groupby("Date"):
                date_str = date.strftime("%Y_%m_%d")  # '2025-03-05' â†’ '2025_03_05'
                save_csv(df_date, date_str, '_'.join(valid_tickers), is_monthly=True)

                for tick in valid_tickers:
                    ticker_data = df_date[df_date['Ticker'] == tick]
                    save_csv(ticker_data, date_str, tick, is_monthly=False)

            break  # ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ë©´ ë£¨í”„ ì¢…ë£Œ

        except Exception as e:
            print(f"[ERROR] ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            if attempt < retries - 1:
                logging.info(f"[INFO] ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨, ì¬ì‹œë„ ì¤‘... (Attempt {attempt + 1}/{retries})")
                time.sleep(5)  # ì¬ì‹œë„ ê°„ì˜ ë”œë ˆì´
            else:
                log_to_db(
                    execution_time=start_time,
                    from_date=from_date,
                    to_date=to_date,
                    tickers=ticker_list,
                    step="FETCH_DATA",
                    status="FAIL",
                    message=f"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}",
                    duration_seconds=(datetime.now() - start_time).total_seconds()
                )

if __name__ == "__main__":
    create_log_table()
    tickers = load_tickers_from_file(TICKER_PATH)

    # ğŸ†• ì»¤ë§¨ë“œë¼ì¸ ì¸ì ì²˜ë¦¬
    parser = argparse.ArgumentParser(description="ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ê¸°")
    parser.add_argument("from_date", type=str, nargs="?", default=None, help="ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)")
    parser.add_argument("to_date", type=str, nargs="?", default=None, help="ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)")

    args = parser.parse_args()

    # ë‚ ì§œ ì„¤ì •
    if args.from_date and args.to_date:
        from_date = args.from_date
        to_date = args.to_date
    else:
        from_date, to_date = get_default_dates()
    logging.info(f"[INFO] {from_date} ~ {to_date}")
    print(f"[INFO] {from_date} ~ {to_date}")

    fetch_stock_data(tickers, from_date, to_date)

