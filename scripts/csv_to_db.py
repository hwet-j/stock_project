import argparse
import subprocess
import os
from datetime import datetime
from dotenv import load_dotenv
import psycopg2
import csv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# PostgreSQL ì—°ê²° ì •ë³´
DB_CONFIG = {
    "host": os.getenv("DB_HOST"),
    "port": os.getenv("DB_PORT"),
    "dbname": os.getenv("DB_NAME"),
    "user": os.getenv("DB_USER"),
    "password": os.getenv("DB_PASS")
}

CSV_LOG_PATH = os.getenv("CSV_LOG_DIR")

TICKER_PATH = os.getenv("TICKER_FILE_PATH")

def create_stock_data_table():
    """ğŸ“Š stock_data í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±)"""
    conn = None
    cur = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()

        create_table_query = """
        CREATE TABLE IF NOT EXISTS stock_data (
            id SERIAL PRIMARY KEY,
            ticker TEXT NOT NULL,
            date DATE NOT NULL,
            open NUMERIC,
            high NUMERIC,
            low NUMERIC,
            close NUMERIC,
            volume BIGINT,
            UNIQUE (ticker, date)
        );
        """
        cur.execute(create_table_query)
        conn.commit()
        print("âœ… stock_data í…Œì´ë¸”ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {e}")

    finally:
        if cur:
            cur.close()
        if conn:
            conn.close()


def create_temp_table():
    """ğŸ“Œ stock_data_temp í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±)"""
    conn = None
    cur = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        cur.execute("""
            CREATE TABLE IF NOT EXISTS stock_data_temp (
                ticker TEXT,
                date DATE,
                open NUMERIC,
                high NUMERIC,
                low NUMERIC,
                close NUMERIC,
                volume BIGINT
            );
        """)
        conn.commit()
        print("âœ… stock_data_temp í…Œì´ë¸”ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {e}")

    finally:
        if cur:
            cur.close()
        if conn:
            conn.close()


def fix_csv_headers(input_file, output_file):
    """CSV íŒŒì¼ í—¤ë” ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´(_)ë¡œ ë³€ê²½"""
    with open(input_file, newline='', encoding='utf-8') as infile, open(output_file, "w", newline='',
                                                                        encoding='utf-8') as outfile:
        reader = csv.reader(infile)
        writer = csv.writer(outfile)

        # í—¤ë” ìˆ˜ì • (ê³µë°± â†’ "_")
        header = next(reader)
        new_header = [col.replace(" ", "_") for col in header]
        writer.writerow(new_header)

        # ë°ì´í„° ê·¸ëŒ€ë¡œ ë³µì‚¬
        for row in reader:
            writer.writerow(row)


def csv_to_db_copy(csv_file, target_table="stock_data"):
    """ğŸ“¥ psql COPY ëª…ë ¹ì–´ë¥¼ ì´ìš©í•˜ì—¬ CSV ë°ì´í„°ë¥¼ PostgreSQLì— ì ì¬"""
    if not os.path.exists(csv_file):
        print(f"âŒ CSV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_file}")
        return False

    # íŒŒì¼ ì´ë¦„ì—ì„œ tickerì™€ ë‚ ì§œ ì¶”ì¶œ
    file_name = os.path.basename(csv_file)
    file_name_without_ext = os.path.splitext(file_name)[0]

    try:
        ticker, date_str = file_name_without_ext.split("_")
        date_formatted = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
    except ValueError:
        print(f"âŒ íŒŒì¼ëª…ì—ì„œ tickerì™€ ë‚ ì§œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_name}")
        return False

    # CSV í—¤ë” ìˆ˜ì •
    fixed_csv_file = csv_file.replace(".csv", "_fixed.csv")
    fix_csv_headers(csv_file, fixed_csv_file)

    conn = None
    cur = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()

        # COPY ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ CSV ë°ì´í„°ë¥¼ í…Œì´ë¸”ì— ì ì¬
        copy_query = f"""
        COPY {target_table} (ticker, date, open, high, low, close, volume)
        FROM STDIN WITH CSV HEADER DELIMITER ',' QUOTE '"';
        """

        # íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ COPY ëª…ë ¹ì–´ ì‹¤í–‰
        with open(fixed_csv_file, "r", encoding="utf-8") as f:
            cur.copy_expert(sql=copy_query, file=f)

        conn.commit()
        print(f"âœ… {csv_file} ë°ì´í„°ê°€ {target_table} í…Œì´ë¸”ì— ì„±ê³µì ìœ¼ë¡œ ì ì¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ CSV ì ì¬ ì‹¤íŒ¨: {e}")
        return False

    finally:
        if cur:
            cur.close()
        if conn:
            conn.close()

    return True



def process_csv_files():
    """ğŸ“‚ ë¡œê·¸ íŒŒì¼ì—ì„œ CSV ëª©ë¡ì„ ì½ì–´ ì²˜ë¦¬"""
    if not os.path.exists(CSV_LOG_PATH):
        print(f"âŒ CSV ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {CSV_LOG_PATH}")
        return
    CSV_LOG_FILE = CSV_LOG_PATH + "/csv_files.log"
    with open(CSV_LOG_FILE, "r") as file:
        csv_files = [line.strip() for line in file.readlines() if line.strip()]

    if not csv_files:
        print("ğŸ“‚ ì ì¬í•  CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“‚ ì´ {len(csv_files)}ê°œì˜ CSV íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    for csv_file_path in csv_files:
        if os.path.exists(csv_file_path):
            success = csv_to_db_copy(csv_file_path)
            if success:
                print(f"âœ… {csv_file_path} ì²˜ë¦¬ ì™„ë£Œ")
        else:
            print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {csv_file_path}")

    print("âœ… ëª¨ë“  CSV íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")


if __name__ == "__main__":
    create_stock_data_table()
    create_temp_table()
    # process_csv_files()
