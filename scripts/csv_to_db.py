import argparse
import subprocess
import os
from datetime import datetime, timedelta
from dotenv import load_dotenv
import psycopg2
from psycopg2 import sql


# .env file load
load_dotenv()

# PostgreSQL ì—°ê²° ì •ë³´ ì„¤ì •
DB_CONFIG = {
    "host": os.getenv("POSTGRES_HOST"),
    "port": os.getenv("POSTGRES_PORT"),
    "dbname": os.getenv("POSTGRES_DB"),
    "user": os.getenv("POSTGRES_USER"),
    "password": os.getenv("POSTGRES_PASSWORD")
}

CSV_LOG_DIR = os.getenv("CSV_LOG_DIR")



def csv_to_db_pgfutter(csv_file_path, table_name="stock_data"):
    """ ğŸ“¥ pgfutterë¥¼ ì´ìš©í•˜ì—¬ CSV ë°ì´í„°ë¥¼ PostgreSQLì— ì ì¬í•˜ëŠ” í•¨ìˆ˜ """
    try:
        start_time = datetime.now()
        schema = "public"
        temp_table = f"{table_name}_temp"

        # PostgreSQL ì—°ê²°
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()

        # 1ï¸âƒ£ ì„ì‹œ í…Œì´ë¸” ìƒì„± (ê¸°ì¡´ stock_data í…Œì´ë¸”ê³¼ ë™ì¼í•œ êµ¬ì¡°)
        create_temp_table_query = sql.SQL(f"""
                    CREATE TABLE IF NOT EXISTS {temp_table} (LIKE {table_name} INCLUDING ALL);
                """)
        cur.execute(create_temp_table_query)
        conn.commit()

        # pgfutter ì‹¤í–‰ ëª…ë ¹ì–´
        command = ["pgfutter", "csv", csv_file_path]
        result = subprocess.run(command, capture_output=True, text=True)

        if result.returncode != 0:
            raise Exception(f"pgfutter ì ì¬ ì‹¤íŒ¨: {result.stderr}")

        # 3ï¸âƒ£ ë°ì´í„° ê²€ì¦
        cur.execute(f"SELECT COUNT(*) FROM {temp_table};")
        temp_count = cur.fetchone()[0]

        if temp_count == 0:
            raise Exception("ì„ì‹œ í…Œì´ë¸”ì— ì ì¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # 4ï¸âƒ£ ê²€ì¦ëœ ë°ì´í„°ë¥¼ stock_data í…Œì´ë¸”ë¡œ ì´ë™
        insert_query = sql.SQL(f"""
                    INSERT INTO {table_name} SELECT * FROM {temp_table}
                    ON CONFLICT (ticker, date) DO NOTHING;
                """)
        cur.execute(insert_query)
        conn.commit()

        # 5ï¸âƒ£ ì„ì‹œ í…Œì´ë¸” ì‚­ì œ
        cur.execute(f"DROP TABLE IF EXISTS {temp_table};")
        conn.commit()

        print(f"âœ… {csv_file_path} ì ì¬ ì„±ê³µ")
        return True

    except Exception as e:
        # âŒ ì‹¤íŒ¨ ì‹œ ì„ì‹œ í…Œì´ë¸” ì‚­ì œ
        conn.rollback()
        cur.execute(f"DROP TABLE IF EXISTS {temp_table};")
        conn.commit()
        print(f"âŒ {csv_file_path} ì ì¬ ì‹¤íŒ¨: {e}")
        return False

    finally:
        if cur:
            cur.close()
        if conn:
            conn.close()


def process_csv_files():
    """ CSV_LOG_DIRì— ìˆëŠ” ëª¨ë“  CSV íŒŒì¼ì„ ì²˜ë¦¬í•œ í›„, ë¡œê·¸ íŒŒì¼ ì‚­ì œ """

    CSV_LOG_DIR_FILES = CSV_LOG_DIR + "/csv_files.log"


    # CSV_LOG_DIRì—ì„œ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    csv_files = sorted([f for f in os.listdir(CSV_LOG_DIR_FILES) if f.endswith(".csv")])

    if not csv_files:
        print("ğŸ“‚ ì ì¬í•  CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“‚ ì´ {len(csv_files)}ê°œì˜ CSV íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    for csv_file in csv_files:
        csv_file_path = os.path.join(CSV_LOG_DIR, csv_file)
        print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {csv_file_path}")
        csv_to_db_pgfutter(csv_file_path)

    # ëª¨ë“  CSV íŒŒì¼ ì²˜ë¦¬ í›„ ë¡œê·¸ íŒŒì¼ ì‚­ì œ
    for csv_file in csv_files:
        csv_file_path = os.path.join(CSV_LOG_DIR, csv_file)
        try:
            os.remove(csv_file_path)
            print(f"ğŸ—‘ï¸ ì‚­ì œ ì™„ë£Œ: {csv_file_path}")
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {csv_file_path} - {e}")

    print("âœ… ëª¨ë“  CSV íŒŒì¼ ì²˜ë¦¬ ë° ë¡œê·¸ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")


if __name__ == "__main__":
    process_csv_files()