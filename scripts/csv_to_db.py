import argparse
import subprocess
import os
from datetime import datetime
from dotenv import load_dotenv
import psycopg2
from psycopg2 import sql
import csv

# .env file load
load_dotenv()

# PostgreSQL ì—°ê²° ì •ë³´ ì„¤ì •
DB_CONFIG = {
    "host": os.getenv("POSTGRES_HOST"),
    "port": os.getenv("POSTGRES_PORT"),
    "dbname": os.getenv("POSTGRES_DB"),
    "user": os.getenv("POSTGRES_USER"),
    "password": os.getenv("POSTGRES_PASSWORD")
}

CSV_LOG_FILE = os.getenv("CSV_LOG_DIR") + "/csv_files.log"  # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ


def create_stock_data_table():
    """ ğŸ“Š stock_data í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìë™ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ """
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()

        create_table_query = """
        CREATE TABLE IF NOT EXISTS stock_data (
            id SERIAL PRIMARY KEY,
            ticker TEXT NOT NULL,
            date DATE NOT NULL,
            open NUMERIC,
            high NUMERIC,
            low NUMERIC,
            close NUMERIC,
            volume BIGINT,
            UNIQUE (ticker, date)
        );
        """

        cur.execute(create_table_query)
        conn.commit()
        print("âœ… stock_data í…Œì´ë¸”ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {e}")

    finally:
        if cur:
            cur.close()
        if conn:
            conn.close()


def fix_csv_headers(input_file, output_file):
    """
    CSV íŒŒì¼ì˜ í—¤ë”ì—ì„œ ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´(_)ë¡œ ë³€ê²½
    """
    with open(input_file, newline='', encoding='utf-8') as infile, open(output_file, "w", newline='', encoding='utf-8') as outfile:
        reader = csv.reader(infile)
        writer = csv.writer(outfile)

        # (1) í—¤ë” ìˆ˜ì •: ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´(_)ë¡œ ë³€ê²½
        header = next(reader)
        new_header = [col.replace(" ", "_") for col in header]  # ê³µë°± â†’ "_"
        writer.writerow(new_header)

        # (2) ë°ì´í„° ê·¸ëŒ€ë¡œ ë³µì‚¬
        for row in reader:
            writer.writerow(row)

# ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜
def log_to_db(execution_time, extraction_date, tickers, step, status, message, duration_seconds):
    conn = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO stock_data_log 
                (execution_time, extraction_date, tickers, step, status, message, duration_seconds) 
                VALUES (%s, %s, %s, %s, %s, %s, %s)
                """,
                (execution_time, extraction_date, tickers, step, status, message, duration_seconds)
            )
            conn.commit()
            # print(f"[INFO] ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {step} - {status}")
    except Exception as e:
        print(f"[ERROR] ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    finally:
        if conn:
            conn.close()



def csv_to_db_pgfutter(csv_file, target_table="stock_data"):
    """ ğŸ“¥ pgfutterë¥¼ ì´ìš©í•˜ì—¬ CSV ë°ì´í„°ë¥¼ PostgreSQLì— ì ì¬í•˜ëŠ” í•¨ìˆ˜ """
    conn = None
    schema = "public"
    table_name = target_table + '_temp'

    start_time = datetime.now()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡


    file_name = os.path.basename(csv_file)
    file_name_without_ext = os.path.splitext(file_name)[0]
    ticker, date_str = file_name_without_ext.split("_")
    date_formatted = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"

    fixed_csv_file = csv_file.replace(".csv", "_fixed.csv")
    fix_csv_headers(csv_file, fixed_csv_file)

    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()

        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        env = os.environ.copy()
        env["DB_NAME"] = DB_CONFIG["dbname"]
        env["DB_USER"] = DB_CONFIG["user"]
        env["DB_PASS"] = DB_CONFIG["password"]
        env["DB_HOST"] = DB_CONFIG["host"]
        env["DB_PORT"] = str(DB_CONFIG["port"])
        env["DB_SCHEMA"] = schema
        env["DB_TABLE"] = table_name

        required_env_vars = [
            "DB_NAME", "DB_USER", "DB_PASS", "DB_HOST", "DB_PORT", "DB_SCHEMA", "DB_TABLE"
        ]

        print("POSTGRES_DB:", os.getenv("POSTGRES_DB"))
        print("POSTGRES_USER:", os.getenv("POSTGRES_USER"))
        print("POSTGRES_PASSWORD:", os.getenv("POSTGRES_PASSWORD"))
        print("POSTGRES_HOST:", os.getenv("POSTGRES_HOST"))
        print("POSTGRES_PORT:", os.getenv("POSTGRES_PORT"))

        # í˜„ì¬ í™˜ê²½ ë³€ìˆ˜ ì¶œë ¥
        print("ğŸ”¹ [INFO] í˜„ì¬ ì„¤ì •ëœ í™˜ê²½ ë³€ìˆ˜ ëª©ë¡:")
        for key, value in os.environ.items():
            if "PASS" in key:
                print(f"{key} = ********")  # ë³´ì•ˆìƒ íŒ¨ìŠ¤ì›Œë“œëŠ” ë§ˆìŠ¤í‚¹ ì²˜ë¦¬
            else:
                print(f"{key} = {value}")

        # í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ì²´í¬
        print("\nğŸ”¹ [INFO] í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì—¬ë¶€ í™•ì¸:")
        missing_vars = []
        for var in required_env_vars:
            if var in os.environ:
                print(f"âœ… {var} = {os.environ[var]}")
            else:
                print(f"âŒ {var} ì´(ê°€) ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
                missing_vars.append(var)

        # ìµœì¢… ê²°ê³¼
        if missing_vars:
            print("\nâ— [ERROR] ì¼ë¶€ í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤:")
            print(", ".join(missing_vars))
        else:
            print("\nâœ… [SUCCESS] ëª¨ë“  í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ì •ìƒì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")

        # âœ… (4) pgfutter ì‹¤í–‰
        command = ["pgfutter", "csv", fixed_csv_file]
        try:
            result = subprocess.run(command, check=True, env=env, capture_output=True, text=True)

            print(f"\nâœ… [INFO] pgfutter ì‹¤í–‰ ì™„ë£Œ (stdout):\n{result.stdout}")
            print(f"\nâš ï¸ [INFO] pgfutter ì˜¤ë¥˜ ë¡œê·¸ (stderr):\n{result.stderr}")

            cur.execute("SELECT tablename FROM pg_tables WHERE schemaname = 'public';")
            tables = cur.fetchall()

            print("\nğŸ”¹ [INFO] í˜„ì¬ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡:")
            for table in tables:
                print(f"   - {table[0]}")

        except subprocess.CalledProcessError as e:
            print(f"\nâŒ [ERROR] pgfutter ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            log_to_db(start_time, date_formatted, ticker, f"LOAD_TO_DB", "ERROR",
                      f"{date_formatted}.{ticker} PGFUTTER EXECUTION ERROR", 0)
            return False

        # âœ… (5) ì¤‘ë³µ ë°ì´í„° ì œê±° í›„, target_tableë¡œ ì´ë™
        cur.execute(f"""
                    DELETE FROM {table_name} 
                    WHERE (ticker, date::TEXT) IN (SELECT ticker, date::TEXT FROM {target_table});
                """)
        conn.commit()

    finally:
        print("\nğŸ”¹ [INFO] ë—.")  # ì¢…ë£Œ ë©”ì‹œì§€
        exit()



def process_csv_files():
    """ ğŸ“‚ ë¡œê·¸ íŒŒì¼ì—ì„œ CSV íŒŒì¼ ëª©ë¡ì„ ì½ì–´ í•˜ë‚˜ì”© ì²˜ë¦¬í•œ í›„, ë¡œê·¸ íŒŒì¼ ì‚­ì œ """

    # 1ï¸âƒ£ CSV ë¡œê·¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(CSV_LOG_FILE):
        print(f"âŒ CSV ë¡œê·¸ íŒŒì¼({CSV_LOG_FILE})ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # 2ï¸âƒ£ ë¡œê·¸ íŒŒì¼ì—ì„œ CSV íŒŒì¼ ëª©ë¡ ì½ê¸°
    with open(CSV_LOG_FILE, "r") as file:
        csv_files = [line.strip() for line in file.readlines() if line.strip()]

    if not csv_files:
        print("ğŸ“‚ ì ì¬í•  CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“‚ ì´ {len(csv_files)}ê°œì˜ CSV íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    # 3ï¸âƒ£ CSV íŒŒì¼ì„ í•˜ë‚˜ì”© ë°ì´í„°ë² ì´ìŠ¤ì— ì ì¬
    for csv_file_path in csv_files:
        if os.path.exists(csv_file_path):
            # print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {csv_file_path}")
            csv_to_db_pgfutter(csv_file_path)
        else:
            print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {csv_file_path}")

    # 4ï¸âƒ£ ëª¨ë“  CSV íŒŒì¼ ì²˜ë¦¬ í›„ ë¡œê·¸ íŒŒì¼ ì‚­ì œ
    try:
        # os.remove(CSV_LOG_FILE)
        print(f"ğŸ—‘ï¸ ë¡œê·¸ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {CSV_LOG_FILE}")
    except Exception as e:
        print(f"âŒ ë¡œê·¸ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")

    print("âœ… ëª¨ë“  CSV íŒŒì¼ ì²˜ë¦¬ ë° ë¡œê·¸ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")


if __name__ == "__main__":
    create_stock_data_table()
    process_csv_files()
