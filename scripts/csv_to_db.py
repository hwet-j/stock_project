import argparse
import subprocess
import os
from datetime import datetime
from dotenv import load_dotenv
import psycopg2
import csv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# PostgreSQL ì—°ê²° ì •ë³´
DB_CONFIG = {
    "host": os.getenv("DB_HOST"),
    "port": os.getenv("DB_PORT"),
    "dbname": os.getenv("DB_NAME"),
    "user": os.getenv("DB_USER"),
    "password": os.getenv("DB_PASS")
}

CSV_LOG_PATH = os.getenv("CSV_LOG_DIR")

TICKER_PATH = os.getenv("TICKER_FILE_PATH")

def create_stock_data_table():
    """ğŸ“Š stock_data í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±)"""
    conn = None
    cur = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()

        create_table_query = """
        CREATE TABLE IF NOT EXISTS stock_data (
            id SERIAL PRIMARY KEY,
            ticker TEXT NOT NULL,
            date DATE NOT NULL,
            open NUMERIC,
            high NUMERIC,
            low NUMERIC,
            close NUMERIC,
            volume BIGINT,
            UNIQUE (ticker, date)
        );
        """
        cur.execute(create_table_query)
        conn.commit()
        print("âœ… stock_data í…Œì´ë¸”ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {e}")

    finally:
        if cur:
            cur.close()
        if conn:
            conn.close()


def create_temp_table():
    """ğŸ“Œ stock_data_temp í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±)"""
    conn = None
    cur = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        cur.execute("""
            CREATE TABLE IF NOT EXISTS stock_data_temp (
                ticker TEXT,
                date DATE,
                open NUMERIC,
                high NUMERIC,
                low NUMERIC,
                close NUMERIC,
                volume BIGINT
            );
        """)
        conn.commit()
        print("âœ… stock_data_temp í…Œì´ë¸”ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {e}")

    finally:
        if cur:
            cur.close()
        if conn:
            conn.close()


def fix_csv_headers(input_file, output_file):
    """CSV íŒŒì¼ í—¤ë” ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´(_)ë¡œ ë³€ê²½"""
    with open(input_file, newline='', encoding='utf-8') as infile, open(output_file, "w", newline='',
                                                                        encoding='utf-8') as outfile:
        reader = csv.reader(infile)
        writer = csv.writer(outfile)

        # í—¤ë” ìˆ˜ì • (ê³µë°± â†’ "_")
        header = next(reader)
        new_header = [col.replace(" ", "_") for col in header]
        writer.writerow(new_header)

        # ë°ì´í„° ê·¸ëŒ€ë¡œ ë³µì‚¬
        for row in reader:
            writer.writerow(row)


def csv_to_db_pgfutter(csv_file, target_table="stock_data"):
    """ğŸ“¥ pgfutterë¥¼ ì´ìš©í•˜ì—¬ CSV ë°ì´í„°ë¥¼ PostgreSQLì— ì ì¬"""

    if not os.path.exists(csv_file):
        print(f"âŒ CSV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_file}")
        return False

    schema = "public"
    table_name = target_table + '_temp'

    start_time = datetime.now()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡

    # íŒŒì¼ ì´ë¦„ì—ì„œ tickerì™€ ë‚ ì§œ ì¶”ì¶œ
    file_name = os.path.basename(csv_file)
    file_name_without_ext = os.path.splitext(file_name)[0]

    try:
        ticker, date_str = file_name_without_ext.split("_")
        date_formatted = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
    except ValueError:
        print(f"âŒ íŒŒì¼ëª…ì—ì„œ tickerì™€ ë‚ ì§œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_name}")
        return False

    # CSV í—¤ë” ìˆ˜ì •
    fixed_csv_file = csv_file.replace(".csv", "_fixed.csv")
    fix_csv_headers(csv_file, fixed_csv_file)

    conn = None
    cur = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()

        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        os.environ.update({
            "DB_NAME": DB_CONFIG["dbname"],
            "DB_USER": DB_CONFIG["user"],
            "DB_PASS": DB_CONFIG["password"],
            "DB_HOST": DB_CONFIG["host"],
            "DB_PORT": str(DB_CONFIG["port"]),
            "DB_SCHEMA": schema,
            "DB_TABLE": table_name
        })

        # âœ… pgfutter ì‹¤í–‰
        command = ["pgfutter", "csv", fixed_csv_file]
        result = subprocess.run(command, check=True, capture_output=True, text=True)

        if result.returncode == 0:
            print(f"\nâœ… [INFO] pgfutter ì‹¤í–‰ ì™„ë£Œ:\n{result.stdout}")
        else:
            print(f"\nâš ï¸ [WARNING] pgfutter ì‹¤í–‰ ì¤‘ ê²½ê³  ë°œìƒ:\n{result.stderr}")

        # âœ… ì¤‘ë³µ ë°ì´í„° ì œê±° í›„ ì´ë™
        cur.execute(f"""
            DELETE FROM {table_name} 
            WHERE (ticker, date) IN (SELECT ticker, date FROM {target_table});
        """)
        conn.commit()

    except subprocess.CalledProcessError as e:
        print(f"\nâŒ [ERROR] pgfutter ì‹¤í–‰ ì‹¤íŒ¨: {e.stderr}")
        return False

    except Exception as e:
        print(f"\nâŒ [ERROR] CSV ì ì¬ ì‹¤íŒ¨: {e}")
        return False

    finally:
        if cur:
            cur.close()
        if conn:
            conn.close()

    print("\nğŸ”¹ [INFO] CSV ì ì¬ ì™„ë£Œ.")
    return True


def process_csv_files():
    """ğŸ“‚ ë¡œê·¸ íŒŒì¼ì—ì„œ CSV ëª©ë¡ì„ ì½ì–´ ì²˜ë¦¬"""
    if not os.path.exists(CSV_LOG_PATH):
        print(f"âŒ CSV ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {CSV_LOG_PATH}")
        return
    CSV_LOG_FILE = CSV_LOG_PATH + "/csv_files.log"
    with open(CSV_LOG_FILE, "r") as file:
        csv_files = [line.strip() for line in file.readlines() if line.strip()]

    if not csv_files:
        print("ğŸ“‚ ì ì¬í•  CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“‚ ì´ {len(csv_files)}ê°œì˜ CSV íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    for csv_file_path in csv_files:
        if os.path.exists(csv_file_path):
            success = csv_to_db_pgfutter(csv_file_path)
            if success:
                print(f"âœ… {csv_file_path} ì²˜ë¦¬ ì™„ë£Œ")
        else:
            print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {csv_file_path}")

    print("âœ… ëª¨ë“  CSV íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")


if __name__ == "__main__":
    create_stock_data_table()
    create_temp_table()
    # process_csv_files()
