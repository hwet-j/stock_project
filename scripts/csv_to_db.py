import argparse
import subprocess
import os
from datetime import datetime
from dotenv import load_dotenv
import psycopg2
from psycopg2 import sql
import csv

# .env file load
load_dotenv()

# PostgreSQL ì—°ê²° ì •ë³´ ì„¤ì •
DB_CONFIG = {
    "host": os.getenv("POSTGRES_HOST"),
    "port": os.getenv("POSTGRES_PORT"),
    "dbname": os.getenv("POSTGRES_DB"),
    "user": os.getenv("POSTGRES_USER"),
    "password": os.getenv("POSTGRES_PASSWORD")
}

CSV_LOG_FILE = os.getenv("CSV_LOG_DIR") + "/csv_files.log"  # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ


def create_stock_data_table():
    """ ğŸ“Š stock_data í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìë™ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ """
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()

        create_table_query = """
        CREATE TABLE IF NOT EXISTS stock_data (
            id SERIAL PRIMARY KEY,
            ticker TEXT NOT NULL,
            date DATE NOT NULL,
            open NUMERIC,
            high NUMERIC,
            low NUMERIC,
            close NUMERIC,
            volume BIGINT,
            UNIQUE (ticker, date)
        );
        """

        cur.execute(create_table_query)
        conn.commit()
        print("âœ… stock_data í…Œì´ë¸”ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ í…Œì´ë¸” ìƒì„± ì˜¤ë¥˜: {e}")

    finally:
        if cur:
            cur.close()
        if conn:
            conn.close()


def fix_csv_headers(input_file, output_file):
    """
    CSV íŒŒì¼ì˜ í—¤ë”ì—ì„œ ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´(_)ë¡œ ë³€ê²½
    """
    with open(input_file, newline='', encoding='utf-8') as infile, open(output_file, "w", newline='', encoding='utf-8') as outfile:
        reader = csv.reader(infile)
        writer = csv.writer(outfile)

        # (1) í—¤ë” ìˆ˜ì •: ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´(_)ë¡œ ë³€ê²½
        header = next(reader)
        new_header = [col.replace(" ", "_") for col in header]  # ê³µë°± â†’ "_"
        writer.writerow(new_header)

        # (2) ë°ì´í„° ê·¸ëŒ€ë¡œ ë³µì‚¬
        for row in reader:
            writer.writerow(row)

def log_to_db(step, log_type, ticker, message, from_date=None, to_date=None, start_time=None, end_time=None, result=None):
    """
    ë³€í™˜ ê³¼ì •ì˜ ë¡œê·¸ë¥¼ stock_data_log í…Œì´ë¸”ì— ì €ì¥

    :param step: ë‹¨ê³„ (ì˜ˆ: 'Parquet ë³€í™˜', 'CSV ì‚­ì œ')
    :param log_type: ë¡œê·¸ ë ˆë²¨ (INFO, ERROR)
    :param ticker: ì¢…ëª© ì½”ë“œ (ì—†ìœ¼ë©´ None)
    :param message: ìƒì„¸ ë©”ì‹œì§€
    :param from_date: ë°ì´í„° ì¡°íšŒ ì‹œì‘ ë‚ ì§œ (ì—†ìœ¼ë©´ None)
    :param to_date: ë°ì´í„° ì¡°íšŒ ì¢…ë£Œ ë‚ ì§œ (ì—†ìœ¼ë©´ None)
    :param start_time: í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì‹œê°„
    :param end_time: í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œê°„
    :param result: ë³€í™˜ ê²°ê³¼ (ì„±ê³µ / ì‹¤íŒ¨)
    """
    conn = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()

        query = """
        INSERT INTO stock_data_log (step, log_type, ticker, message, from_date, to_date, start_time, end_time, result, created_at)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, NOW());
        """
        cur.execute(query, (step, log_type, ticker, message, from_date, to_date, start_time, end_time, result))

        conn.commit()
        cur.close()
    except Exception as e:
        print(f"[DB ë¡œê·¸ ì˜¤ë¥˜] {e}")
    finally:
        if conn:
            conn.close()

def csv_to_db_pgfutter(csv_file, target_table="stock_data"):
    """ ğŸ“¥ pgfutterë¥¼ ì´ìš©í•˜ì—¬ CSV ë°ì´í„°ë¥¼ PostgreSQLì— ì ì¬í•˜ëŠ” í•¨ìˆ˜ """
    conn = None
    schema = "public"
    table_name = target_table + '_temp'

    #
    fixed_csv_file = csv_file.replace(".csv", "_fixed.csv")
    fix_csv_headers(csv_file, fixed_csv_file)

    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()

        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        env = os.environ.copy()
        env["DB_NAME"] = DB_CONFIG["dbname"]
        env["DB_USER"] = DB_CONFIG["user"]
        env["DB_PASS"] = DB_CONFIG["password"]
        env["DB_HOST"] = DB_CONFIG["host"]
        env["DB_PORT"] = str(DB_CONFIG["port"])
        env["DB_SCHEMA"] = schema
        env["DB_TABLE"] = table_name

        # pgfutter ì‹¤í–‰ ëª…ë ¹ì–´
        command = [
            "pgfutter", "csv",
            fixed_csv_file  # ì‚½ì…í•  CSV íŒŒì¼
        ]

        try:
            result = subprocess.run(command, check=True, env=env, capture_output=True, text=True)
            print(f"[INFO] CSV ë°ì´í„°ë¥¼ '{schema}.{table_name}' í…Œì´ë¸”ì— ì €ì¥ ì™„ë£Œ")
            log_to_db("CSV ì ì¬", "INFO", "ALL", f"pgfutter ì‹¤í–‰ ì™„ë£Œ: {result.stdout}")
        except subprocess.CalledProcessError as e:
            print(f"[ERROR] pgfutter ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            log_to_db("CSV ì ì¬", "ERROR", "ALL", f"pgfutter ì‹¤í–‰ ì‹¤íŒ¨: {e.stderr}")
            return False

        # âœ… (2) ì¤‘ë³µ ë°ì´í„° ì œê±° í›„, target_tableë¡œ ì´ë™
        cur.execute(f"""
                DELETE FROM {table_name} 
                WHERE (ticker, date::TEXT) IN (SELECT ticker, date::TEXT FROM {target_table});
            """)
        conn.commit()
        # print(f"[INFO] ì¤‘ë³µ ë°ì´í„° ì œê±° ì™„ë£Œ")

        cur.execute(f"""
                INSERT INTO {target_table} (date, open, high, low, close, volume, dividends, stock_splits, ticker)
                SELECT 
                    date::DATE, 
                    NULLIF(REPLACE(open, '\r', ''), '')::NUMERIC, 
                    NULLIF(REPLACE(high, '\r', ''), '')::NUMERIC, 
                    NULLIF(REPLACE(low, '\r', ''), '')::NUMERIC, 
                    NULLIF(REPLACE(close, '\r', ''), '')::NUMERIC, 
                    NULLIF(REPLACE(volume, '\r', ''), '')::NUMERIC, 
                    NULLIF(REPLACE(dividends, '\r', ''), '')::NUMERIC, 
                    NULLIF(REPLACE(stock_splits, '\r', ''), '')::NUMERIC, 
                    REPLACE(ticker, '\r', '')
                FROM {table_name};
            """)
        conn.commit()

        print(f"[INFO] ë°ì´í„° `{target_table}`ë¡œ ì´ë™ ì™„ë£Œ")

        # âœ… (3) ì›ë³¸ í…Œì´ë¸” ì‚­ì œ
        cur.execute(f"DROP TABLE {table_name};")
        conn.commit()
        # print(f"[INFO] ìë™ ìƒì„±ëœ í…Œì´ë¸” `{table_name}` ì‚­ì œ ì™„ë£Œ")

        return True

    except subprocess.CalledProcessError as e:
        print(f"[Error] pgfutter ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return False

    except Exception as e:
        print(f"[Error] ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

    finally:
        if conn:
            conn.close()


def process_csv_files():
    """ ğŸ“‚ ë¡œê·¸ íŒŒì¼ì—ì„œ CSV íŒŒì¼ ëª©ë¡ì„ ì½ì–´ í•˜ë‚˜ì”© ì²˜ë¦¬í•œ í›„, ë¡œê·¸ íŒŒì¼ ì‚­ì œ """

    # 1ï¸âƒ£ CSV ë¡œê·¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(CSV_LOG_FILE):
        print(f"âŒ CSV ë¡œê·¸ íŒŒì¼({CSV_LOG_FILE})ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    # 2ï¸âƒ£ ë¡œê·¸ íŒŒì¼ì—ì„œ CSV íŒŒì¼ ëª©ë¡ ì½ê¸°
    with open(CSV_LOG_FILE, "r") as file:
        csv_files = [line.strip() for line in file.readlines() if line.strip()]

    if not csv_files:
        print("ğŸ“‚ ì ì¬í•  CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“‚ ì´ {len(csv_files)}ê°œì˜ CSV íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    # 3ï¸âƒ£ CSV íŒŒì¼ì„ í•˜ë‚˜ì”© ë°ì´í„°ë² ì´ìŠ¤ì— ì ì¬
    for csv_file_path in csv_files:
        if os.path.exists(csv_file_path):
            print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {csv_file_path}")
            csv_to_db_pgfutter(csv_file_path)
        else:
            print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {csv_file_path}")

    # 4ï¸âƒ£ ëª¨ë“  CSV íŒŒì¼ ì²˜ë¦¬ í›„ ë¡œê·¸ íŒŒì¼ ì‚­ì œ
    try:
        # os.remove(CSV_LOG_FILE)
        print(f"ğŸ—‘ï¸ ë¡œê·¸ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {CSV_LOG_FILE}")
    except Exception as e:
        print(f"âŒ ë¡œê·¸ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")

    print("âœ… ëª¨ë“  CSV íŒŒì¼ ì²˜ë¦¬ ë° ë¡œê·¸ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")


if __name__ == "__main__":
    create_stock_data_table()
    process_csv_files()
