import argparse
import logging
import time

import yfinance as yf
import os
from datetime import datetime, timedelta
import pandas_market_calendars as mcal
from dotenv import load_dotenv
import psycopg2
from psycopg2 import sql



# .env file load
load_dotenv()

# PostgreSQL ì—°ê²° ì •ë³´ ì„¤ì •
DB_CONFIG = {
    "host": os.getenv("DB_HOST"),
    "port": os.getenv("DB_PORT"),
    "dbname": os.getenv("DB_NAME"),
    "user": os.getenv("DB_USER"),
    "password": os.getenv("DB_PASS")
}

CSV_DIR = os.getenv("CSV_DIR")

CSV_LOG_DIR = os.getenv("CSV_LOG_DIR")

"""
assert CSV_DIR, "CSV_DIR í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
for key, value in DB_CONFIG.items():
    assert value, f"{key} í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
"""

LOG_TABLE_NAME = "stock_data_log"

TICKER_PATH = os.getenv("TICKER_FILE_PATH")

def create_log_table():
    """ ğŸ“‘ ë¡œê·¸ ì €ì¥ì„ ìœ„í•œ í…Œì´ë¸” ìƒì„± í•¨ìˆ˜ """
    create_table_query = sql.SQL(f"""
    CREATE TABLE IF NOT EXISTS {LOG_TABLE_NAME} (
        id SERIAL PRIMARY KEY,
        execution_time TIMESTAMP NOT NULL,
        extraction_date DATE NOT NULL,
        tickers TEXT NOT NULL,
        step TEXT NOT NULL,
        status TEXT NOT NULL,
        message TEXT,
        duration_seconds DOUBLE PRECISION
    );
    """)

    conn = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        with conn.cursor() as cur:
            cur.execute(create_table_query)
            conn.commit()
            # print(f"[INFO] í…Œì´ë¸” '{LOG_TABLE_NAME}' ìƒì„± ì™„ë£Œ ë˜ëŠ” ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"[ERROR] í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
    finally:
        if conn:
            conn.close()

def is_market_closed(date):
    nyse = mcal.get_calendar("NYSE")
    holidays = nyse.holidays().holidays
    is_weekend = date.weekday() in [5,6]

    return date in holidays or is_weekend

def load_tickers_from_file(file_path: str) -> list:
    """ğŸ“‚ íŒŒì¼ì—ì„œ Ticker ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜"""
    tickers = []
    try:
        with open(file_path, "r") as f:
            tickers = [line.strip() for line in f if line.strip()]  # ë¹ˆ ì¤„ ì œì™¸
        print(f"[INFO] Ticker {len(tickers)}ê°œ ë¡œë“œ ì™„ë£Œ")
    except FileNotFoundError:
        print(f"[ERROR] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    except Exception as e:
        print(f"[ERROR] Ticker íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return tickers

def get_default_dates() -> tuple:
    """ğŸ—“ï¸ ê¸°ë³¸ ë‚ ì§œë¥¼ ì „ë‚ ë¡œ ì„¤ì •"""
    yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
    return yesterday, yesterday


# ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜
def log_to_db(execution_time, extraction_date, tickers, step, status, message, duration_seconds):
    conn = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO stock_data_log 
                (execution_time, extraction_date, tickers, step, status, message, duration_seconds) 
                VALUES (%s, %s, %s, %s, %s, %s, %s)
                """,
                (execution_time, extraction_date, tickers, step, status, message, duration_seconds)
            )
            conn.commit()
            # print(f"[INFO] ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {step} - {status}")
    except Exception as e:
        print(f"[ERROR] ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    finally:
        if conn:
            conn.close()


def save_csv(data, extract_date, ticker=None):
    """ CSV íŒŒì¼ì„ ì €ì¥í•˜ê³  ë¡œê·¸ë¥¼ ë‚¨ê¸°ëŠ” í•¨ìˆ˜ """
    try:
        start_time = datetime.now()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡

        # ğŸ“… ë‚ ì§œ ê¸°ë°˜ í´ë” êµ¬ì¡° ìƒì„±
        date_folder = extract_date.strftime("%Y/%m")
        save_folder = os.path.join(CSV_DIR, date_folder)
        os.makedirs(save_folder, exist_ok=True)
        # os.chmod(save_folder, 0o755)  # ê¶Œí•œ ì„¤ì •

        # ğŸ“„ íŒŒì¼ëª…ì— ë‚ ì§œ í¬í•¨
        date_str = extract_date.strftime("%Y%m%d")
        file_path = None

        # âœ… Tickerë³„ ì €ì¥ ì—¬ë¶€ì— ë”°ë¼ Stepê³¼ Message ì„¤ì •
        if ticker:
            file_name = f"{ticker}_{date_str}.csv"
            step = "SAVE_CSV_TICKER"
            file_path = os.path.join(save_folder, file_name)
            message = f"{ticker} Data: {file_path} ì €ì¥ ì™„ë£Œ"
            ticker_info = ticker
        else:
            file_name = f"ALL_{date_str}.csv"
            step = "SAVE_CSV_ALL"
            file_path = os.path.join(save_folder, file_name)
            message = f"ALL Data: {file_path} ì €ì¥ ì™„ë£Œ"
            ticker_info = "ALL"


        # CSV ì €ì¥
        data.to_csv(file_path, index=False)
        # print(f"[INFO] CSV ì €ì¥ ì™„ë£Œ: {file_path}")

        # ì €ì¥ ê²½ë¡œë¥¼ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
        log_file_path = CSV_LOG_DIR

        with open(log_file_path, "a") as log_file:
            log_file.write(file_path + "\n")

        duration_seconds = (datetime.now() - start_time).total_seconds()
        # ğŸ“ ë¡œê·¸ ì‘ì„±
        log_to_db(
            execution_time=datetime.now(),
            extraction_date=extract_date,
            tickers=ticker_info,
            step=step,
            status="SUCCESS",
            message=message,
            duration_seconds=duration_seconds
        )

        return file_path
    except Exception as e:
        # print(f"[ERROR] CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        duration_seconds = (datetime.now() - start_time).total_seconds()

        log_to_db(datetime.now(),
                  extract_date,
                  ticker or "ALL",
                  step,
                  "FAIL",
                  f"CSV ì €ì¥ ì‹¤íŒ¨: {e}",
                  duration_seconds)
        return None




# ì£¼ì‹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
def fetch_stock_data(tickers, from_date, to_date):
    extract_date = datetime.strptime(from_date, "%Y-%m-%d")
    end_date = datetime.strptime(to_date, "%Y-%m-%d")

    log_to_db(execution_time=datetime.now(),
              extraction_date=extract_date,
              tickers=','.join(tickers),
              step="START",
              status="START",
              message="ë°ì´í„° ì¶”ì¶œ ì‹œì‘",
              duration_seconds=0)

    while extract_date <= end_date:
        if is_market_closed(extract_date):
            print(f"[SKIP] íœ´ì¥ì¼: {extract_date.strftime('%Y-%m-%d')}")

            log_to_db(execution_time=datetime.now(),
                      extraction_date=extract_date,
                      tickers="ALL",
                      step="FETCH_DATA",
                      status="SKIP",
                      message="íœ´ì¥ì¼",
                      duration_seconds=0)
            extract_date += timedelta(days=1)
            continue
        else:
            try:
                start_time = datetime.now()  # ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ì‹œê°„

                # ë°ì´í„° ë‹¤ìš´ë¡œë“œì— ëŒ€í•œ ì¬ì‹œë„ ë¡œì§ ì¶”ê°€
                retries = 3
                for attempt in range(retries):
                    try:
                        stock_data = yf.download(
                            tickers,
                            start=extract_date.strftime("%Y-%m-%d"),
                            end=(extract_date + timedelta(days=1)).strftime("%Y-%m-%d"),
                            group_by='ticker',
                            auto_adjust=True
                        )
                        if stock_data.empty:
                            print("[WARN] ë°ì´í„° ì—†ìŒ")

                            log_to_db(
                                execution_time=start_time,
                                extraction_date=extract_date,
                                tickers="ALL",
                                step="FETCH_DATA",
                                status="FAIL",
                                message="ë°ì´í„° ì—†ìŒ",
                                duration_seconds=(datetime.now() - start_time).total_seconds()
                            )
                            break  # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë‹¤ìŒë‚ ë¡œ ë„˜ì–´ê°
                        else:
                            # ğŸ“‚ ì „ì²´ ë°ì´í„° CSV ì €ì¥
                            # all_file_path = save_csv(stock_data, extract_date)

                            #  ğŸ” tickerë³„ CSV ì €ì¥
                            for ticker in tickers:
                                if ticker in stock_data.columns.levels[0]:  # ë°ì´í„°ê°€ ìˆëŠ” tickerë§Œ ì €ì¥
                                    # print(f"[INFO] Ticker ë°ì´í„° ì €ì¥: {ticker}")

                                    ticker_data = stock_data[ticker].reset_index()
                                    ticker_data["ticker"] = ticker
                                    save_csv(ticker_data, extract_date, ticker=ticker)
                                else:  # ë°ì´í„°ê°€ ì—†ëŠ” ticker ë¡œê·¸ ì²˜ë¦¬
                                    print(f"[WARN] Ticker {ticker} ë°ì´í„° ì—†ìŒ")

                                    log_to_db(
                                        execution_time=start_time,
                                        extraction_date=extract_date,
                                        tickers=ticker,
                                        step="SAVE_CSV_TICKER",
                                        status="FAIL",
                                        message=f"Ticker {ticker} ë°ì´í„° ì—†ìŒ",
                                        duration_seconds=(datetime.now() - start_time).total_seconds()
                                    )
                            break  # ì„±ê³µì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í–ˆìœ¼ë©´ ë£¨í”„ ì¢…ë£Œ
                    except Exception as e:
                        print(f"[ERROR] ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                        if attempt < retries - 1:
                            logging.info(f"[INFO] {ticker} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨, ì¬ì‹œë„ ì¤‘... (Attempt {attempt + 1}/{retries})")
                            time.sleep(5)  # ì¬ì‹œë„ ê°„ì˜ ë”œë ˆì´
                        else:
                            log_to_db(
                                execution_time=start_time,
                                extraction_date=extract_date,
                                tickers="ALL",
                                step="FETCH_DATA",
                                status="FAIL",
                                message=f"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}",
                                duration_seconds=(datetime.now() - start_time).total_seconds()
                            )
            except Exception as e:
                print(f"[ERROR] ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

                log_to_db(
                    execution_time=start_time,
                    extraction_date=extract_date,
                    tickers="ALL",
                    step="FETCH_DATA",
                    status="FAIL",
                    message=f"ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}",
                    duration_seconds=(datetime.now() - start_time).total_seconds()
                )

            extract_date += timedelta(days=1)


if __name__ == "__main__":
    create_log_table()
    tickers = load_tickers_from_file(TICKER_PATH)

    # ğŸ†• ì»¤ë§¨ë“œë¼ì¸ ì¸ì ì²˜ë¦¬
    parser = argparse.ArgumentParser(description="ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ê¸°")
    parser.add_argument("from_date", type=str, nargs="?", default=None, help="ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)")
    parser.add_argument("to_date", type=str, nargs="?", default=None, help="ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)")

    args = parser.parse_args()

    # ë‚ ì§œ ì„¤ì •
    if args.from_date and args.to_date:
        from_date = args.from_date
        to_date = args.to_date
    else:
        from_date, to_date = get_default_dates()

    fetch_stock_data(tickers, from_date, to_date)

