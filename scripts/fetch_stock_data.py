import argparse
import logging
import time

import pandas as pd
import yfinance as yf
import os
from datetime import datetime, timedelta
import pandas_market_calendars as mcal
from dotenv import load_dotenv
import psycopg2
from psycopg2 import sql



# .env file load
load_dotenv()

# PostgreSQL ì—°ê²° ì •ë³´ ì„¤ì •
DB_CONFIG = {
    "host": os.getenv("DB_HOST"),
    "port": os.getenv("DB_PORT"),
    "dbname": os.getenv("DB_NAME"),
    "user": os.getenv("DB_USER"),
    "password": os.getenv("DB_PASS")
}

CSV_DIR = os.getenv("CSV_DIR")

CSV_LOG_DIR = os.getenv("CSV_LOG_DIR")

"""
assert CSV_DIR, "CSV_DIR í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
for key, value in DB_CONFIG.items():
    assert value, f"{key} í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
"""

LOG_TABLE_NAME = "stock_data_log"

TICKER_PATH = os.getenv("TICKER_FILE_PATH")

def create_log_table():
    """ ğŸ“‘ ë¡œê·¸ ì €ì¥ì„ ìœ„í•œ í…Œì´ë¸” ìƒì„± í•¨ìˆ˜ """
    create_table_query = sql.SQL(f"""
    CREATE TABLE IF NOT EXISTS {LOG_TABLE_NAME} (
        id SERIAL PRIMARY KEY,
        execution_time TIMESTAMP NOT NULL,
        from_date DATE NOT NULL,
        to_date DATE NOT NULL,
        tickers TEXT NOT NULL,
        step TEXT NOT NULL,
        status TEXT NOT NULL,
        message TEXT,
        duration_seconds DOUBLE PRECISION
    );
    """)

    conn = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        with conn.cursor() as cur:
            cur.execute(create_table_query)
            conn.commit()
            # print(f"[INFO] í…Œì´ë¸” '{LOG_TABLE_NAME}' ìƒì„± ì™„ë£Œ ë˜ëŠ” ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"[ERROR] í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
    finally:
        if conn:
            conn.close()

def is_market_closed(date):
    nyse = mcal.get_calendar("NYSE")
    holidays = nyse.holidays().holidays
    is_weekend = date.weekday() in [5,6]

    return date in holidays or is_weekend

def load_tickers_from_file(file_path: str) -> list:
    """ğŸ“‚ íŒŒì¼ì—ì„œ Ticker ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜"""
    tickers = []
    try:
        with open(file_path, "r") as f:
            tickers = [line.strip() for line in f if line.strip()]  # ë¹ˆ ì¤„ ì œì™¸
        print(f"[INFO] Ticker {len(tickers)}ê°œ ë¡œë“œ ì™„ë£Œ")
    except FileNotFoundError:
        print(f"[ERROR] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    except Exception as e:
        print(f"[ERROR] Ticker íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return tickers

def get_default_dates() -> tuple:
    """ğŸ—“ï¸ ê¸°ë³¸ ë‚ ì§œë¥¼ ì „ë‚ ë¡œ ì„¤ì •"""
    today = datetime.now().strftime("%Y-%m-%d")
    yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")

    return yesterday, today


# ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜
def log_to_db(execution_time, from_date, to_date, tickers, step, status, message, duration_seconds):
    conn = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO stock_data_log 
                (execution_time, from_date, to_date, tickers, step, status, message, duration_seconds) 
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                """,
                (execution_time, from_date, to_date, tickers, step, status, message, duration_seconds)
            )
            conn.commit()
            # print(f"[INFO] ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {step} - {status}")
    except Exception as e:
        print(f"[ERROR] ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    finally:
        if conn:
            conn.close()


def save_csv(data, extract_date, ticker_list):
    """ CSV íŒŒì¼ì„ ì €ì¥í•˜ê³  ë¡œê·¸ë¥¼ ë‚¨ê¸°ëŠ” í•¨ìˆ˜ """
    start_time = datetime.now()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡
    try:
        # ğŸ“… ë‚ ì§œ ê¸°ë°˜ í´ë” êµ¬ì¡° ìƒì„±
        date_folder = extract_date.strftime("%Y/%m")
        save_folder = os.path.join(CSV_DIR, date_folder)
        os.makedirs(save_folder, exist_ok=True)
        # os.chmod(save_folder, 0o755)  # ê¶Œí•œ ì„¤ì •


        # âœ… Tickerë³„ ì €ì¥ ì—¬ë¶€ì— ë”°ë¼ Stepê³¼ Message ì„¤ì •
        file_name = f"stock_data_{extract_date}.csv"
        step = "SAVE_CSV_TICKER"
        file_path = os.path.join(save_folder, file_name)
        message = f"Data: {file_path} ì €ì¥ ì™„ë£Œ"


        # CSV ì €ì¥
        data.to_csv(file_path, index=False)
        # print(f"[INFO] CSV ì €ì¥ ì™„ë£Œ: {file_path}")

        # ì €ì¥ ê²½ë¡œë¥¼ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
        log_file_path = CSV_LOG_DIR

        with open(log_file_path, "a") as log_file:
            log_file.write(file_path + "\n")

        duration_seconds = (datetime.now() - start_time).total_seconds()
        # ğŸ“ ë¡œê·¸ ì‘ì„±
        log_to_db(
            execution_time=datetime.now(),
            from_date=extract_date,
            to_date=extract_date,
            tickers=ticker_list,
            step="SAVE_CSV",
            status="SUCCESS",
            message=message,
            duration_seconds=duration_seconds
        )

        return file_path
    except Exception as e:
        print(f"[ERROR] CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        duration_seconds = (datetime.now() - start_time).total_seconds()

        log_to_db(execution_time=datetime.now(),
                  from_date=extract_date,
                  to_date=extract_date,
                  tickers=ticker_list,
                  step="SAVE_CSV",
                  status="FAIL",
                  message=f"CSV ì €ì¥ ì‹¤íŒ¨: {e}",
                  duration_seconds=duration_seconds)
        return None




# ì£¼ì‹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
def fetch_stock_data(tickers, from_date, to_date):
    ticker_list = ','.join(tickers)
    extraction_date = f"{from_date} ~ {to_date}"
    # ë°ì´í„° ì¶”ì¶œ ì‹œì‘
    log_to_db(execution_time=datetime.now(),
              from_date=from_date,
              to_date=to_date,
              tickers=ticker_list,
              step="START",
              status="START",
              message="ë°ì´í„° ì¶”ì¶œ ì‹œì‘",
              duration_seconds=0)

    start_time = datetime.now()  # ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ì‹œê°„

    # ë°ì´í„° ë‹¤ìš´ë¡œë“œì— ëŒ€í•œ ì¬ì‹œë„ ë¡œì§ ì¶”ê°€
    retries = 3
    for attempt in range(retries):
        try:
            # ticker, from_date, to_date í•´ë‹¹í•˜ëŠ” ë°ì´í„° ìˆ˜ì§‘
            stock_data = yf.download(tickers, start=from_date, end=to_date)
            if stock_data.empty:
                print("[WARN] ë°ì´í„° ì—†ìŒ")

                log_to_db(
                    execution_time=start_time,
                    from_date=from_date,
                    to_date=to_date,
                    tickers=ticker_list,
                    step="FETCH_DATA",
                    status="FAIL",
                    message="ë°ì´í„° ì—†ìŒ",
                    duration_seconds=(datetime.now() - start_time).total_seconds()
                )
            else:
                #  ğŸ” ticker ì»¬ëŸ¼ ìƒì„± ë° tickerë³„ ë°ì´í„° ë¶„ë¦¬
                data_list = []
                for ticker in tickers:
                    df_ticker = stock_data.xs(ticker, axis=1, level=1)  # íŠ¹ì • ticker ë°ì´í„° ì¶”ì¶œ
                    df_ticker.insert(0, "Ticker", ticker)  # Ticker ì»¬ëŸ¼ ì¶”ê°€
                    data_list.append(df_ticker)  # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€

                # âœ… ëª¨ë“  Ticker ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ ë³‘í•©
                df_final = pd.concat(data_list).reset_index()

                # âœ… í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
                df_final = df_final[['Date', 'Ticker', 'Close', 'High', 'Low', 'Open', 'Volume']]

                # âœ… ë‚ ì§œë³„ë¡œ ë‚˜ëˆ  ì €ì¥ (íŒŒì¼ëª…: stock_data_YYYY_MM_DD.csv)
                for date, df_date in df_final.groupby("Date"):
                    date_str = date.strftime("%Y_%m_%d")  # '2025-03-05' â†’ '2025_03_05'
                    save_csv(df_date, date, ticker_list)

                # ë°ì´í„° ë‹¤ìš´ ë° ì €ì¥ ì™„ë£Œì‹œ ë£¨í”„ íƒˆì¶œ
                break
        except Exception as e:
            print(f"[ERROR] ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            if attempt < retries - 1:
                logging.info(f"[INFO] {ticker} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨, ì¬ì‹œë„ ì¤‘... (Attempt {attempt + 1}/{retries})")
                time.sleep(5)  # ì¬ì‹œë„ ê°„ì˜ ë”œë ˆì´
            else:
                log_to_db(
                    execution_time=start_time,
                    from_date=from_date,
                    to_date=to_date,
                    tickers=ticker_list,
                    step="FETCH_DATA",
                    status="FAIL",
                    message=f"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}",
                    duration_seconds=(datetime.now() - start_time).total_seconds()
                )


if __name__ == "__main__":
    create_log_table()
    tickers = load_tickers_from_file(TICKER_PATH)

    # ğŸ†• ì»¤ë§¨ë“œë¼ì¸ ì¸ì ì²˜ë¦¬
    parser = argparse.ArgumentParser(description="ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ê¸°")
    parser.add_argument("from_date", type=str, nargs="?", default=None, help="ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)")
    parser.add_argument("to_date", type=str, nargs="?", default=None, help="ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)")

    args = parser.parse_args()

    # ë‚ ì§œ ì„¤ì •
    if args.from_date and args.to_date:
        from_date = args.from_date
        to_date = args.to_date
    else:
        from_date, to_date = get_default_dates()

    fetch_stock_data(tickers, from_date, to_date)

