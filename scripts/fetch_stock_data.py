import argparse
import yfinance as yf
import os
from datetime import datetime, timedelta
import pandas_market_calendars as mcal
from dotenv import load_dotenv
import psycopg2
from psycopg2 import sql



# .env file load
load_dotenv()

# PostgreSQL ì—°ê²° ì •ë³´ ì„¤ì •
DB_CONFIG = {
    "host": os.getenv("POSTGRES_HOST"),
    "port": os.getenv("POSTGRES_PORT"),
    "dbname": os.getenv("POSTGRES_DB"),
    "user": os.getenv("POSTGRES_USER"),
    "password": os.getenv("POSTGRES_PASSWORD")
}

CSV_DIR = os.getenv("CSV_DIR")

CSV_LOG_DIR = os.getenv("CSV_LOG_DIR")

"""
assert CSV_DIR, "CSV_DIR í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
for key, value in DB_CONFIG.items():
    assert value, f"{key} í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
"""

LOG_TABLE_NAME = "stock_data_log"

TICKER_PATH = os.getenv("TICKER_FILE_PATH")

def create_log_table():
    """ ğŸ“‘ ë¡œê·¸ ì €ì¥ì„ ìœ„í•œ í…Œì´ë¸” ìƒì„± í•¨ìˆ˜ """
    create_table_query = sql.SQL(f"""
    CREATE TABLE IF NOT EXISTS {LOG_TABLE_NAME} (
        id SERIAL PRIMARY KEY,
        execution_time TIMESTAMP NOT NULL,
        extraction_date DATE NOT NULL,
        tickers TEXT NOT NULL,
        step TEXT NOT NULL,
        status TEXT NOT NULL,
        message TEXT,
        duration_seconds DOUBLE PRECISION
    );
    """)

    conn = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        with conn.cursor() as cur:
            cur.execute(create_table_query)
            conn.commit()
            # print(f"[INFO] í…Œì´ë¸” '{LOG_TABLE_NAME}' ìƒì„± ì™„ë£Œ ë˜ëŠ” ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"[ERROR] í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
    finally:
        if conn:
            conn.close()

def is_market_closed(date):
    nyse = mcal.get_calendar("NYSE")
    holidays = nyse.holidays().holidays
    is_weekend = date.weekday() in [5,6]

    return date in holidays or is_weekend

def load_tickers_from_file(file_path: str) -> list:
    """ğŸ“‚ íŒŒì¼ì—ì„œ Ticker ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜"""
    tickers = []
    try:
        with open(file_path, "r") as f:
            tickers = [line.strip() for line in f if line.strip()]  # ë¹ˆ ì¤„ ì œì™¸
        print(f"[INFO] Ticker {len(tickers)}ê°œ ë¡œë“œ ì™„ë£Œ")
    except FileNotFoundError:
        print(f"[ERROR] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    except Exception as e:
        print(f"[ERROR] Ticker íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return tickers

def get_default_dates() -> tuple:
    """ğŸ—“ï¸ ê¸°ë³¸ ë‚ ì§œë¥¼ ì „ë‚ ë¡œ ì„¤ì •"""
    yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
    return yesterday, yesterday


# ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜
def log_to_db(execution_time, extraction_date, tickers, step, status, message, duration_seconds):
    conn = None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO stock_data_log 
                (execution_time, extraction_date, tickers, step, status, message, duration_seconds) 
                VALUES (%s, %s, %s, %s, %s, %s, %s)
                """,
                (execution_time, extraction_date, tickers, step, status, message, duration_seconds)
            )
            conn.commit()
            # print(f"[INFO] ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {step} - {status}")
    except Exception as e:
        print(f"[ERROR] ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    finally:
        if conn:
            conn.close()


def save_csv(data, extract_date, ticker=None):
    """ CSV íŒŒì¼ì„ ì €ì¥í•˜ê³  ë¡œê·¸ë¥¼ ë‚¨ê¸°ëŠ” í•¨ìˆ˜ """
    try:
        start_time = datetime.now()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡

        # ğŸ“… ë‚ ì§œ ê¸°ë°˜ í´ë” êµ¬ì¡° ìƒì„±
        date_folder = extract_date.strftime("%Y/%m")
        save_folder = os.path.join(CSV_DIR, date_folder)
        os.makedirs(save_folder, exist_ok=True)
        # os.chmod(save_folder, 0o755)  # ê¶Œí•œ ì„¤ì •

        # ğŸ“„ íŒŒì¼ëª…ì— ë‚ ì§œ í¬í•¨
        date_str = extract_date.strftime("%Y%m%d")
        file_path = None

        # âœ… Tickerë³„ ì €ì¥ ì—¬ë¶€ì— ë”°ë¼ Stepê³¼ Message ì„¤ì •
        if ticker:
            file_name = f"{ticker}_{date_str}.csv"
            step = "SAVE_CSV_TICKER"
            file_path = os.path.join(save_folder, file_name)
            message = f"{ticker} Data: {file_path} ì €ì¥ ì™„ë£Œ"
            ticker_info = ticker
        else:
            file_name = f"ALL_{date_str}.csv"
            step = "SAVE_CSV_ALL"
            file_path = os.path.join(save_folder, file_name)
            message = f"ALL Data: {file_path} ì €ì¥ ì™„ë£Œ"
            ticker_info = "ALL"


        # CSV ì €ì¥
        data.to_csv(file_path, index=False)
        # print(f"[INFO] CSV ì €ì¥ ì™„ë£Œ: {file_path}")

        # ì €ì¥ ê²½ë¡œë¥¼ ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
        log_file_path = os.path.join(CSV_LOG_DIR, "csv_files.log")  # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ìƒì„±
        os.makedirs(os.path.dirname(log_file_path), exist_ok=True)

        with open(log_file_path, "a") as log_file:
            log_file.write(file_path + "\n")

        duration_seconds = (datetime.now() - start_time).total_seconds()
        # ğŸ“ ë¡œê·¸ ì‘ì„±
        log_to_db(
            execution_time=datetime.now(),
            extraction_date=extract_date,
            tickers=ticker_info,
            step=step,
            status="SUCCESS",
            message=message,
            duration_seconds=duration_seconds
        )

        return file_path
    except Exception as e:
        # print(f"[ERROR] CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        duration_seconds = (datetime.now() - start_time).total_seconds()

        log_to_db(datetime.now(),
                  extract_date,
                  ticker or "ALL",
                  step,
                  "FAIL",
                  f"CSV ì €ì¥ ì‹¤íŒ¨: {e}",
                  duration_seconds)
        return None

import subprocess



# ì£¼ì‹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
def fetch_stock_data(tickers, from_date, to_date):
    extract_date = datetime.strptime(from_date, "%Y-%m-%d")
    end_date = datetime.strptime(to_date, "%Y-%m-%d")

    log_to_db(execution_time=datetime.now(),
              extraction_date=extract_date,
              tickers=','.join(tickers),
              step="START",
              status="START",
              message="ë°ì´í„° ì¶”ì¶œ ì‹œì‘",
              duration_seconds=0)

    while extract_date <= end_date:
        if is_market_closed(extract_date):
            print(f"[SKIP] íœ´ì¥ì¼: {extract_date.strftime('%Y-%m-%d')}")

            log_to_db(execution_time=datetime.now(),
                      extraction_date=extract_date,
                      tickers="ALL",
                      step="FETCH_DATA",
                      status="SKIP",
                      message="íœ´ì¥ì¼",
                      duration_seconds=0)
            extract_date += timedelta(days=1)
            continue
        else:
            try:
                start_time = datetime.now()  # ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ì‹œê°„
                # print(f"[STEP] ì£¼ì‹ ë°ì´í„° ë‹¤ìš´ë¡œë“œ: {tickers}")

                stock_data = yf.download(
                    tickers,
                    start=extract_date.strftime("%Y-%m-%d"),
                    end=(extract_date + timedelta(days=1)).strftime("%Y-%m-%d"),
                    group_by='ticker',
                    auto_adjust=True
                )
                if stock_data.empty:
                    print("[WARN] ë°ì´í„° ì—†ìŒ")

                    log_to_db(
                        execution_time = start_time,
                        extraction_date = extract_date,
                        tickers = "ALL",
                        step = "FETCH_DATA",
                        status = "FAIL",
                        message = "ë°ì´í„° ì—†ìŒ",
                        duration_seconds = (datetime.now() - start_time).total_seconds()
                    )
                else:
                    # ğŸ“‚ ì „ì²´ ë°ì´í„° CSV ì €ì¥
                    all_file_path = save_csv(stock_data, extract_date)

                    #  ğŸ” tickerë³„ CSV ì €ì¥
                    for ticker in tickers:
                        if ticker in stock_data.columns.levels[0]:  # ë°ì´í„°ê°€ ìˆëŠ” tickerë§Œ ì €ì¥
                            # print(f"[INFO] Ticker ë°ì´í„° ì €ì¥: {ticker}")

                            ticker_data = stock_data[ticker].reset_index()
                            save_csv(ticker_data, extract_date, ticker=ticker)
                        else:   # ë°ì´í„°ê°€ ì—†ëŠ” ticker ë¡œê·¸ ì²˜ë¦¬
                            print(f"[WARN] Ticker {ticker} ë°ì´í„° ì—†ìŒ")

                            log_to_db(
                                execution_time=start_time,
                                extraction_date=extract_date,
                                tickers=ticker,
                                step="SAVE_CSV_TICKER",
                                status="FAIL",
                                message=f"Ticker {ticker} ë°ì´í„° ì—†ìŒ",
                                duration_seconds=(datetime.now() - start_time).total_seconds()
                            )
            except Exception as e:
                print(f"[ERROR] ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

                log_to_db(
                    execution_time = start_time,
                    extraction_date = extract_date,
                    tickers = "ALL",
                    step = "FETCH_DATA",
                    status = "FAIL",
                    message = f"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}",
                    duration_seconds=(datetime.now() - start_time).total_seconds()
                )

            extract_date += timedelta(days=1)


if __name__ == "__main__":
    create_log_table()

    tickers = load_tickers_from_file(TICKER_PATH)

    # ğŸ†• ì»¤ë§¨ë“œë¼ì¸ ì¸ì ì²˜ë¦¬
    parser = argparse.ArgumentParser(description="ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ê¸°")
    parser.add_argument("--from_date", type=str, help="ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)")
    parser.add_argument("--to_date", type=str, help="ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)")

    args = parser.parse_args()

    # ë‚ ì§œ ì„¤ì •
    if args.from_date and args.to_date:
        from_date = args.from_date
        to_date = args.to_date
    else:
        from_date, to_date = get_default_dates()
        # print(f"[INFO] ë‚ ì§œ ì¸ìê°€ ì—†ì–´ì„œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •: {from_date} ~ {to_date}")

    fetch_stock_data(tickers, from_date, to_date)

